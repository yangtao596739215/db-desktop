package integration

import (
	"bufio"
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"time"

	"db-desktop/backend/models"
	"db-desktop/backend/utils"
)

// AIRequest represents the request structure for AI API
type AIRequest struct {
	Model       string            `json:"model"`
	Messages    []*models.Message `json:"messages"`
	Temperature float64           `json:"temperature,omitempty"`
	Stream      bool              `json:"stream,omitempty"`
	Tools       []models.MCPTool  `json:"tools,omitempty"`
	ToolChoice  string            `json:"tool_choice,omitempty"`
	MaxTokens   int               `json:"max_tokens,omitempty"`
}

// AIResponse represents the complete response structure from AI API
type AIResponse struct {
	ID      string   `json:"id"`
	Object  string   `json:"object"`
	Created int64    `json:"created"`
	Model   string   `json:"model"`
	Choices []Choice `json:"choices"`
	Usage   Usage    `json:"usage"`
	Error   *AIError `json:"error,omitempty"`
}

// Choice represents a choice in the AI response
type Choice struct {
	Index        int            `json:"index"`
	Message      models.Message `json:"message"`
	Delta        models.Message `json:"delta,omitempty"` // For streaming responses
	FinishReason string         `json:"finish_reason"`
}

// Usage represents token usage information
type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

// AIError represents an error from the AI API
type AIError struct {
	Message string `json:"message"`
	Type    string `json:"type"`
	Code    string `json:"code,omitempty"`
}

// AIConfig represents AI model configuration
type AIConfig struct {
	APIKey      string  `json:"apiKey"`
	BaseURL     string  `json:"baseURL"`
	Temperature float64 `json:"temperature"`
	Stream      bool    `json:"stream"`
}

// ChatCompletionChunk represents a streaming response chunk
type ChatCompletionChunk struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Delta struct {
			Role      string               `json:"role,omitempty"`
			Content   string               `json:"content,omitempty"`
			ToolCalls []models.MCPToolCall `json:"tool_calls,omitempty"`
		} `json:"delta"`
		Index        int    `json:"index"`
		FinishReason string `json:"finish_reason,omitempty"`
	} `json:"choices"`
}

// CompleteResponse represents the complete response after processing stream
type CompleteResponse struct {
	Content      string
	ToolCalls    []*models.MCPToolCall
	FinishReason string
}

// AIClient handles AI API calls
type AIClient struct {
	config     AIConfig
	client     *http.Client
	configFile string
}

// NewAIClient creates a new AI client
func NewAIClient(config AIConfig) *AIClient {
	homeDir, _ := os.UserHomeDir()
	configFile := filepath.Join(homeDir, ".db-desktop", "ai_config.json")

	return &AIClient{
		config:     config,
		configFile: configFile,
		client: &http.Client{
			Timeout: 60 * time.Second,
		},
	}
}

// LoadConfig loads AI configuration from file
func (c *AIClient) LoadConfig() error {
	// åˆ›å»ºé…ç½®ç›®å½•
	configDir := filepath.Dir(c.configFile)
	if err := os.MkdirAll(configDir, 0755); err != nil {
		utils.Errorf("Failed to create AI config directory: %v", err)
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	// æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(c.configFile); os.IsNotExist(err) {
		utils.Infof("No AI config file found, using default config")
		return nil // æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
	}

	data, err := os.ReadFile(c.configFile)
	if err != nil {
		utils.Errorf("Failed to read AI config file: %v", err)
		return fmt.Errorf("failed to read AI config file: %w", err)
	}

	var config AIConfig
	if err := json.Unmarshal(data, &config); err != nil {
		utils.Errorf("Failed to unmarshal AI config: %v", err)
		return fmt.Errorf("failed to unmarshal AI config: %w", err)
	}

	c.config = config
	apiKeyDisplay := config.APIKey
	if len(apiKeyDisplay) > 10 {
		apiKeyDisplay = apiKeyDisplay[:10] + "..."
	}
	utils.Infof("Loaded AI config from file: apiKey=%s, temperature=%f, stream=%t",
		apiKeyDisplay, config.Temperature, config.Stream)
	return nil
}

// SaveConfig saves AI configuration to file
func (c *AIClient) SaveConfig() error {
	// åˆ›å»ºé…ç½®ç›®å½•
	configDir := filepath.Dir(c.configFile)
	if err := os.MkdirAll(configDir, 0755); err != nil {
		return fmt.Errorf("failed to create config directory: %w", err)
	}

	data, err := json.MarshalIndent(c.config, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal AI config: %w", err)
	}

	if err := os.WriteFile(c.configFile, data, 0644); err != nil {
		return fmt.Errorf("failed to write AI config file: %w", err)
	}

	utils.Infof("Successfully saved AI config to file")
	return nil
}

// UpdateConfig updates AI configuration and saves to file
func (c *AIClient) UpdateConfig(newConfig AIConfig) error {
	c.config = newConfig
	return c.SaveConfig()
}

// GetConfig returns the current AI configuration
func (c *AIClient) GetConfig() AIConfig {
	return c.config
}

// ProcessStreamResponse processes streaming response and returns CompleteResponse
func ProcessStreamResponse(stream io.Reader, callback func(ChatCompletionChunk)) (*CompleteResponse, error) {
	scanner := bufio.NewScanner(stream)
	completeResponse := &CompleteResponse{
		ToolCalls: make([]*models.MCPToolCall, 0),
	}

	// ç”¨äºç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°ï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºkeyï¼ˆå› ä¸ºæµå¼å“åº”ä¸­IDå¯èƒ½ä¸ºç©ºï¼‰
	toolCallArgs := make(map[int]*strings.Builder)
	toolCallMap := make(map[int]*models.MCPToolCall)
	toolCallIndex := 0

	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "data: ") {
			data := strings.TrimPrefix(line, "data: ")

			// æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸæ ‡è®°
			if data == "[DONE]" {
				break
			}

			// è§£æJSONæ•°æ®
			var chunk ChatCompletionChunk
			if err := json.Unmarshal([]byte(data), &chunk); err != nil {
				utils.Warnf("Failed to parse JSON chunk: %v, data: %s", err, data)
				continue // è·³è¿‡è§£æå¤±è´¥çš„chunk
			}

			// è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ¯ä¸ªchunkçš„tool_callsä¿¡æ¯
			if len(chunk.Choices) > 0 && len(chunk.Choices[0].Delta.ToolCalls) > 0 {
				utils.Infof("Received tool_calls chunk: count=%d", len(chunk.Choices[0].Delta.ToolCalls))
				for i, tc := range chunk.Choices[0].Delta.ToolCalls {
					utils.Infof("  ToolCall[%d]: ID='%s', Name='%s', Args='%s'",
						i, tc.ID, tc.Function.Name, tc.Function.Arguments)
				}
			}

			// è°ƒç”¨å›è°ƒå‡½æ•°
			if callback != nil {
				callback(chunk)
			}

			// å¤„ç†æ¯ä¸ªé€‰æ‹©
			for _, choice := range chunk.Choices {
				// ç´¯ç§¯å†…å®¹
				if choice.Delta.Content != "" {
					completeResponse.Content += choice.Delta.Content
				}

				// å¤„ç†å·¥å…·è°ƒç”¨
				for _, toolCall := range choice.Delta.ToolCalls {
					// æ£€æŸ¥æ˜¯å¦æ˜¯æ–°å·¥å…·è°ƒç”¨çš„å¼€å§‹ï¼ˆæœ‰IDè¡¨ç¤ºæ–°å·¥å…·è°ƒç”¨ï¼‰
					if toolCall.ID != "" {
						// æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¿™ä¸ªIDçš„å·¥å…·è°ƒç”¨
						var existingIndex int = -1
						for i, existingToolCall := range toolCallMap {
							if existingToolCall.ID == toolCall.ID {
								existingIndex = i
								break
							}
						}

						if existingIndex == -1 {
							// æ–°å·¥å…·è°ƒç”¨ï¼Œåˆ›å»ºæ–°çš„æ¡ç›®
							toolCallMap[toolCallIndex] = &models.MCPToolCall{
								ID:   toolCall.ID,
								Type: "function",
								Function: models.MCPFunctionCall{
									Name:      toolCall.Function.Name,
									Arguments: "",
								},
							}
							toolCallArgs[toolCallIndex] = &strings.Builder{}
							toolCallIndex++
						}
					}

					// æ‰¾åˆ°å¯¹åº”çš„å·¥å…·è°ƒç”¨è¿›è¡Œæ›´æ–°
					var targetIndex int = -1
					if toolCall.ID != "" {
						// é€šè¿‡IDæŸ¥æ‰¾
						for i, existingToolCall := range toolCallMap {
							if existingToolCall.ID == toolCall.ID {
								targetIndex = i
								break
							}
						}
					} else if toolCallIndex > 0 {
						// å¦‚æœæ²¡æœ‰IDï¼Œä½¿ç”¨æœ€æ–°çš„å·¥å…·è°ƒç”¨
						targetIndex = toolCallIndex - 1
					}

					if targetIndex >= 0 {
						// æ›´æ–°å·¥å…·è°ƒç”¨IDï¼ˆå¦‚æœæä¾›äº†ï¼‰
						if toolCall.ID != "" {
							toolCallMap[targetIndex].ID = toolCall.ID
						}

						// æ›´æ–°å‡½æ•°åï¼ˆå¦‚æœæä¾›äº†ï¼‰
						if toolCall.Function.Name != "" {
							toolCallMap[targetIndex].Function.Name = toolCall.Function.Name
						}

						// ç´¯ç§¯å‚æ•°
						if toolCall.Function.Arguments != "" {
							if toolCallArgs[targetIndex] == nil {
								toolCallArgs[targetIndex] = &strings.Builder{}
							}
							toolCallArgs[targetIndex].WriteString(toolCall.Function.Arguments)
						}
					}
				}

				// è®°å½•å®ŒæˆåŸå› 
				if choice.FinishReason != "" {
					completeResponse.FinishReason = choice.FinishReason
				}
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("è¯»å–æµå¤±è´¥: %v", err)
	}

	// è®¾ç½®ç´¯ç§¯çš„å‚æ•°å¹¶æ·»åŠ åˆ°ç»“æœä¸­
	for i := 0; i < toolCallIndex; i++ {
		if toolCall, exists := toolCallMap[i]; exists {
			if builder, exists := toolCallArgs[i]; exists {
				toolCall.Function.Arguments = builder.String()
			}
			completeResponse.ToolCalls = append(completeResponse.ToolCalls, toolCall)

			// è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æœ€ç»ˆçš„å·¥å…·è°ƒç”¨ä¿¡æ¯
			utils.Infof("Final tool call[%d]: ID='%s', Type='%s', Name='%s', Args='%s'",
				i, toolCall.ID, toolCall.Type, toolCall.Function.Name, toolCall.Function.Arguments)
		}
	}

	utils.Infof("Processed streaming response: content length=%d, tool calls count=%d",
		len(completeResponse.Content), len(completeResponse.ToolCalls))

	return completeResponse, nil
}

// SendMessageStreamWithCompleteResponse sends a message and returns CompleteResponse directly
func (c *AIClient) SendMessageStreamWithCompleteResponse(messages []*models.Message, callback func(ChatCompletionChunk), tools []models.MCPTool) (*CompleteResponse, error) {
	// è®¾ç½®é»˜è®¤çš„BaseURL
	baseURL := c.config.BaseURL
	if baseURL == "" {
		baseURL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
	}

	// Create the request with tools enabled for MCP detection
	req := AIRequest{
		Model:       "qwen-plus", // å›ºå®šä½¿ç”¨åƒé—®æ¨¡å‹
		Messages:    messages,
		Temperature: c.config.Temperature,
		Stream:      true,
		Tools:       tools, // å¯ç”¨å·¥å…·ä»¥æ£€æµ‹MCPè°ƒç”¨
		ToolChoice:  "auto",
		MaxTokens:   2000,
	}

	// Marshal the request
	reqBody, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	// Print request details for debugging (streaming)
	utils.Infof("ğŸ“¤ Streaming request details: url=%s, method=%s, bodySize=%d, stream=%t", baseURL, "POST", len(reqBody), true)

	// Print request body (formatted JSON)
	var prettyJSON bytes.Buffer
	if err := json.Indent(&prettyJSON, reqBody, "", "  "); err == nil {
		utils.Infof("ğŸ“¤ Streaming request body: %s", prettyJSON.String())
	} else {
		utils.Infof("ğŸ“¤ Streaming request body (raw): %s", string(reqBody))
	}

	// Create HTTP request
	httpReq, err := http.NewRequestWithContext(
		context.Background(),
		"POST",
		baseURL,
		bytes.NewBuffer(reqBody),
	)
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	// Set headers
	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("Authorization", "Bearer "+c.config.APIKey)
	httpReq.Header.Set("Accept", "text/event-stream")

	// Print headers
	apiKeyDisplay := c.config.APIKey
	if len(apiKeyDisplay) > 10 {
		apiKeyDisplay = apiKeyDisplay[:10] + "..."
	}
	utils.Infof("ğŸ“¤ Streaming request headers: Content-Type=%s, Authorization=%s, Accept=%s, User-Agent=%s",
		httpReq.Header.Get("Content-Type"),
		"Bearer "+apiKeyDisplay,
		httpReq.Header.Get("Accept"),
		httpReq.Header.Get("User-Agent"))

	// Send the request
	resp, err := c.client.Do(httpReq)
	if err != nil {
		return nil, fmt.Errorf("failed to send request: %w", err)
	}
	defer resp.Body.Close()

	// Check for HTTP errors
	if resp.StatusCode != http.StatusOK {
		respBody, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("HTTP error: %d %s", resp.StatusCode, string(respBody))
	}

	// ä½¿ç”¨æ–°çš„æµå¼å“åº”å¤„ç†
	completeResponse, err := ProcessStreamResponse(resp.Body, callback)
	if err != nil {
		return nil, err
	}

	utils.Infof("ğŸ“¤ SendMessageStreamWithCompleteResponse request %v, completeResponse: %v", req, completeResponse)
	return completeResponse, nil
}

// min returns the smaller of two integers
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
